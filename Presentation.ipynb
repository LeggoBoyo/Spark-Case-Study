{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chase Middleman, Steven Weld, Daniel Jimenez, Zohaib Khawaja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the [data](https://s3.us-east-2.amazonaws.com/jgartner-test-data/twitter/zippedData.zip) provided to us by Twitter, we sought after first cleaning up the data by removing any unnecessary columns.  We went through the data dictionary provided by Twitter object by object to determine which ones would be useful to our analysis.  We then separated the data into either tweets supporting Macron, tweets supporting Le Pen, or tweets that weren't supporting either of them, the third category which would be excluded from further analysis.  Each tweet would have specific entities that we would look at, most importantly hashtags, mentions/tags, and whether or not the tweet had been retweeted or favorited.  Finally, we made a scatterplot of approximate locations of tweets sent out in support of either candidate with hopes of finding correlations between home locations and support.\n",
    "\n",
    "For the sake of this project's scope, we assume that all mentions of a candidate in a given tweet is an acknowledgement of support for said candidate.  It could be said that there is no such thing as bad publicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import pyspark as ps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .master(\"local[4]\") \\\n",
    "            .appName(\"df case study\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "sc = ps.SparkContext\n",
    "tweets_df = spark.read.json('./data/french_tweets.json').sample(False, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the code to only necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns, expand and remove nested columns based on needed keys\n",
    "def CleanUp(rdd, columns):\n",
    "    return (rdd[columns].withColumn('user_id', rdd['user.id'])\n",
    "            .withColumn('user_screen_name', rdd['user.screen_name'])\n",
    "            .withColumn('place_type', rdd['place.place_type'])\n",
    "            .withColumn('place_coordinates', rdd['place.bounding_box.coordinates'])\n",
    "            .withColumn('hashtags', rdd['entities.hashtags.text'])\n",
    "            .withColumn('mentions_id', rdd['entities.user_mentions.id'])\n",
    "            .drop('user')\n",
    "            .drop('place')\n",
    "            .drop('entities')\n",
    "           )\n",
    "\n",
    "cleaned = CleanUp(tweets_df, ['entities', 'filter_level', 'id', 'in_reply_to_user_id', \n",
    "    'lang', 'place', 'possibly_sensitive', 'text', 'timestamp_ms', 'user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned.createOrReplaceTempView(\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- filter_level: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- in_reply_to_user_id: long (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- possibly_sensitive: boolean (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- timestamp_ms: string (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- user_screen_name: string (nullable = true)\n",
      " |-- place_type: string (nullable = true)\n",
      " |-- place_coordinates: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- mentions_id: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Determining whether a tweet is in support of Macron or Le Pen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If a tweet mentions either candidate, replies to either candidate, or has a hashtag that contains either candidate's name, we mark that up as being in support of said candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate public Twitter IDs\n",
    "le_pen_id = 217749896\n",
    "macron_id = 1976143068\n",
    "\n",
    "le_pen_support = -1\n",
    "macron_support = 1\n",
    "\n",
    "# Find out if the candidates ID is mentioned in the tweet, returns -1 for Le Pen, 1 for Macron, or 0 for neither/both\n",
    "def GetSupport(col):\n",
    "    if le_pen_id in col and macron_id in col:\n",
    "        return 0\n",
    "    elif le_pen_id in col:\n",
    "        return le_pen_support\n",
    "    elif macron_id in col:\n",
    "        return macron_support\n",
    "    else:\n",
    "        return 0\n",
    "    pass\n",
    "\n",
    "udf_func = udf(GetSupport, IntegerType())\n",
    "cleaned = cleaned.withColumn('supports', udf_func(F.col('mentions_id')))\n",
    "no_tags = cleaned.withColumn('amount_hashtags', F.size(F.col('hashtags'))).filter(F.col('amount_hashtags') > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-16b6863bcd9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpd_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpd_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coord_estimates'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place_coordinates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords_estimate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-16b6863bcd9c>\u001b[0m in \u001b[0;36mcoords_estimate\u001b[0;34m(entry)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0mcoordinates\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbounding\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     '''\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpd_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def coords_estimate(entry):\n",
    "    '''\n",
    "    params: row: the individual row of the dataframe\n",
    "    returns: an array of length 2 with the average x and y coordinates of the bounding box.\n",
    "    '''\n",
    "    coords = np.array(entry[0])\n",
    "    return np.mean(coords, axis = 0) \n",
    "pd_df = cleaned.toPandas()\n",
    "pd_df['coord_estimates'] = pd_df['place_coordinates'].dropna().apply(coords_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
